from langgraph.graph import START, END, StateGraph
from langchain_openai import ChatOpenAI
from typing import TypedDict, Literal
from pydantic import BaseModel, Field
from dotenv import load_dotenv

load_dotenv()

model = ChatOpenAI(model='gpt-4o-mini')

# Define the schema for sentiment classification
class SentimentSchema(BaseModel):
    sentiment : Literal['Positive', 'Negative'] = Field(description="Sentiment of the review")

# Create a structured model for sentiment analysis
structured_model = model.with_structured_output(SentimentSchema)

# Define the schema for diagnosing a negative review
class DiagnosisSchema(BaseModel):
    issue_type : Literal["UX","Performance","Bug","Support","Other"] = Field(description="The category of issue mentioned in the review")
    tone : Literal["angry","frustated","disappointed","calm"] = Field(description="The emotional tone expressed by the user")
    urgency : Literal["low","medium","high"] = Field(description="How urgent or critical the issue appears to be")

# Create a structured model for diagnosis
structured_model_2 = model.with_structured_output(DiagnosisSchema)

# Define a ReviewState typed dictionary to hold review, sentiment, diagnosis, and response
class ReviewState(TypedDict):
    review : str
    sentiment : Literal['Positive','Negative']
    diagnosis : dict
    response : str

# Nodes Definition
def find_sentiment(state : ReviewState):
    prompt = f"For the following review, find out the sentiment \n {state['review']}"
    sentiment = structured_model.invoke(prompt).sentiment

    return {'sentiment' : sentiment}

def check_sentiment(state : ReviewState) -> Literal['positive_response','run_diagnosis']:
    if state['sentiment'] == 'Positive':
        return 'positive_response'
    else:
        return 'run_diagnosis'

def positive_response(state : ReviewState):
    prompt = f"""Write a warm thank-you message in response to this review: \n \n {state['review']}
                Also, kindly ask the user to leave feedback on our websiteË€"""
    response = model.invoke(prompt).content

    return {'response' : response}

def run_diagnosis(state : ReviewState):
    prompt = f"""Diagnose this negative review: \n \n {state['review']} \n Return issue_type, tone, and urgency."""

    response = structured_model_2.invoke(prompt)

    return {'diagnosis' : response.model_dump()}

def negative_response(state : ReviewState):
    diagnosis = state['diagnosis']
    prompt = f"""You are a support assistant. The user had a {diagnosis['issue_type']} issue, sounded {diagnosis['tone']} 
                and marked urgency as {diagnosis['urgency']} . Write an empathetic, helpful resolution message."""
    
    response = model.invoke(prompt).content

    return {'response' : response}
    
# Initialize the graph
graph = StateGraph(ReviewState)

# Add nodes to the graph
graph.add_node('find_sentiment',find_sentiment)
graph.add_node('positive_response',positive_response)
graph.add_node('run_diagnosis',run_diagnosis)
graph.add_node('negative_response',negative_response)

# Add edges to the graph
graph.add_edge(START,'find_sentiment')
graph.add_conditional_edges('find_sentiment',check_sentiment)
graph.add_edge('positive_response',END)
graph.add_edge('run_diagnosis','negative_response')
graph.add_edge('negative_response',END)

# compile the graph
workflow = graph.compile()

initial_state = {
    'review' : "The product was really good"
}

# Execute the graph
final_state = workflow.invoke(initial_state)

print(final_state)

png_bytes = workflow.get_graph().draw_mermaid_png()

output_file = "conditional-workflow/review-reply-workflow.png"

# Write the PNG to disk
with open(output_file, "wb") as f:
    f.write(png_bytes)